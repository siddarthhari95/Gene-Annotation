{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing Libraries </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Loading +/- Data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive and negative data sets as dataframe\n",
    "positive_data = pd.read_csv('../deep_annotator_data/positive_sample.txt', header=None, nrows=1000)\n",
    "positive_data.columns = [\"Gene\"]\n",
    "negative_data = pd.read_csv('../deep_annotator_data/negative_sample.txt', header=None, nrows=1000)\n",
    "negative_data.columns = [\"Gene\"]\n",
    "data_ = pd.concat([positive_data, negative_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Hyper Parameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "embedding_size = 5\n",
    "window = 1\n",
    "fc_layer_size = (len(positive_data.Gene[0])-(window-1))*embedding_size\n",
    "hidden_layer_size = 100\n",
    "num_layers = 2\n",
    "epochs = 100\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generate word IDs <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4}\n"
     ]
    }
   ],
   "source": [
    "strings = set()\n",
    "def allLexicographicRecur (string, data, last, index): \n",
    "    length = len(string)\n",
    "    for i in range(length): \n",
    "        data[index] = string[i] \n",
    "        if index==last:\n",
    "            res = ''.join(data)\n",
    "            strings.add(res)\n",
    "        else: \n",
    "            allLexicographicRecur(string, data, last, index+1) \n",
    "def allLexicographic(string, n): \n",
    "    length = len(string)\n",
    "    data = [\"\"] * (length+1)\n",
    "    string = sorted(string) \n",
    "    allLexicographicRecur(string, data, window-1, 0)\n",
    "string = \"01234\"\n",
    "allLexicographic(string, window)\n",
    "strings = sorted(strings)\n",
    "vocabulary = {}\n",
    "for val, i in enumerate(strings):\n",
    "    vocabulary[i] = val\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generate Word Embeddings </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeds = nn.Embedding(len(vocabulary), 5)\n",
    "# embeddings = {}\n",
    "# def generate_embeddings():\n",
    "#     for word in vocabulary:\n",
    "#         embeddings[word] = embeds(torch.tensor(vocabulary[word], dtype=torch.long)).type(torch.LongTensor)\n",
    "\n",
    "# generate_embeddings()\n",
    "# print(embeddings['0'].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(data_sample):\n",
    "    list_of_tensors = []\n",
    "    for data in data_sample.itertuples():\n",
    "        for i in range(len(data.Gene) - window + 1):\n",
    "            if i == 0:\n",
    "                first_tensor = embeddings[data.Gene[i:i+window]]\n",
    "            else:\n",
    "                first_tensor = torch.cat((first_tensor, embeddings[data.Gene[i:i+window]]), 0)\n",
    "        list_of_tensors.append(first_tensor)\n",
    "    trainpositives = torch.stack(list_of_tensors)\n",
    "    return trainpositives\n",
    "\n",
    "# positives = generate_samples(positive_data)\n",
    "# print(positives.type())\n",
    "# negatives = generate_samples(negative_data)\n",
    "# print(negatives.type())\n",
    "# data_ = torch.cat([positives, negatives], dim=0)\n",
    "# print(data_.type())\n",
    "\n",
    "negative_labels = torch.zeros(negatives.shape[0], 1)\n",
    "positive_labels = torch.ones(positives.shape[0], 1)\n",
    "labels_ = torch.cat([positive_labels, negative_labels], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Neural Network Layer Implementation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.embeds = nn.Embedding(len(vocabulary), 5)\n",
    "        self.lstm = nn.LSTM(fc_layer_size, fc_layer_size, num_layers)\n",
    "        self.fc1 = nn.Linear(fc_layer_size, hidden_layer_size)\n",
    "        self.relu1 = nn.Sigmoid()\n",
    "        self.out = nn.Linear(hidden_layer_size, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = autograd.Variable(torch.randn(num_layers, batch_size, fc_layer_size))\n",
    "        c = autograd.Variable(torch.randn(num_layers, batch_size, fc_layer_size))\n",
    "        z = self.embeds(x).view((1,-1))\n",
    "#         print(z)\n",
    "#         out_lstm, hn = self.lstm(z, (h, c))\n",
    "        a1 = self.fc1(z)\n",
    "        h1 = self.relu1(a1)\n",
    "        a3 = self.out(h1)\n",
    "        y = self.out_act(a3)\n",
    "        return y\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Optimizer step and loss calculation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(net.parameters(), lr, momentum=0.0)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Train method </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size=1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    c = 0\n",
    "    for data in data_.itertuples():\n",
    "        \n",
    "        data_batch = torch.tensor([vocabulary[data.Gene[i:i+window]] for i in range(0, len(data.Gene) - window + 1)], dtype=torch.long)\n",
    "        labels_batch = labels_[c]\n",
    "        c+=1\n",
    "        data_batch = autograd.Variable(data_batch)\n",
    "        labels_batch = autograd.Variable(labels_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # Extend the side of the data_batch to adhere to LSTM layer implementation\n",
    "        # data_batch.unsqueeze_(0)\n",
    "        # data_batch = data_batch.expand(1, batch_size, fc_layer_size)\n",
    "        labels_hat = net(data_batch)\n",
    "        \n",
    "        # Compute the binary Cross Entropy Loss\n",
    "        loss = criterion(labels_hat, labels_batch)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    loss = sum(losses)/len(losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss at epoch, 0 : 0.046304432549281044\n",
      "Average Loss at epoch, 2 : 0.06557600355957402\n",
      "Average Loss at epoch, 4 : 0.04237065669041476\n",
      "Average Loss at epoch, 6 : 0.028904671456970392\n",
      "Average Loss at epoch, 8 : 0.024026454277598534\n",
      "Average Loss at epoch, 10 : 0.020993312279793827\n",
      "Average Loss at epoch, 12 : 0.018478478838262164\n",
      "Average Loss at epoch, 14 : 0.01660286415192178\n",
      "Average Loss at epoch, 16 : 0.01520521594021602\n",
      "Average Loss at epoch, 18 : 0.014141474395715534\n",
      "Average Loss at epoch, 20 : 0.013318969024315145\n",
      "Average Loss at epoch, 22 : 0.012608414226350263\n",
      "Average Loss at epoch, 24 : 0.01189078192320261\n",
      "Average Loss at epoch, 26 : 0.011199211213542235\n",
      "Average Loss at epoch, 28 : 0.010625393995910642\n",
      "Average Loss at epoch, 30 : 0.010094715364414562\n",
      "Average Loss at epoch, 32 : 0.009591535569974831\n",
      "Average Loss at epoch, 34 : 0.009101976967259319\n",
      "Average Loss at epoch, 36 : 0.00862817637571272\n",
      "Average Loss at epoch, 38 : 0.00822585036047154\n",
      "Average Loss at epoch, 40 : 0.007886459284637815\n",
      "Average Loss at epoch, 42 : 0.007539081716959643\n",
      "Average Loss at epoch, 44 : 0.007171449041471675\n",
      "Average Loss at epoch, 46 : 0.0067958169364163296\n",
      "Average Loss at epoch, 48 : 0.006443972249923796\n",
      "Average Loss at epoch, 50 : 0.0061248134926005305\n",
      "Average Loss at epoch, 52 : 0.005817552237712334\n",
      "Average Loss at epoch, 54 : 0.0054931179042065495\n",
      "Average Loss at epoch, 56 : 0.005151993095367082\n",
      "Average Loss at epoch, 58 : 0.004814263337837168\n",
      "Average Loss at epoch, 60 : 0.004495311422584891\n",
      "Average Loss at epoch, 62 : 0.004196057749308196\n",
      "Average Loss at epoch, 64 : 0.003911328433542245\n",
      "Average Loss at epoch, 66 : 0.003631820091107521\n",
      "Average Loss at epoch, 68 : 0.0033537365295565353\n",
      "Average Loss at epoch, 70 : 0.0030714787371220495\n",
      "Average Loss at epoch, 72 : 0.0027828731409049326\n",
      "Average Loss at epoch, 74 : 0.002493517008681266\n",
      "Average Loss at epoch, 76 : 0.002210321013575758\n",
      "Average Loss at epoch, 78 : 0.0019387984544021607\n",
      "Average Loss at epoch, 80 : 0.0016864018515077887\n",
      "Average Loss at epoch, 82 : 0.0014579690452621605\n",
      "Average Loss at epoch, 84 : 0.00125524336680418\n",
      "Average Loss at epoch, 86 : 0.0010797925759338228\n",
      "Average Loss at epoch, 88 : 0.0009322771506017773\n",
      "Average Loss at epoch, 90 : 0.000811475814511013\n",
      "Average Loss at epoch, 92 : 0.00071428088202466\n",
      "Average Loss at epoch, 94 : 0.0006365348770668575\n",
      "Average Loss at epoch, 96 : 0.0005740666820147098\n",
      "Average Loss at epoch, 98 : 0.0005233231227382973\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train():\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        loss = train_epoch(net, opt, criterion, batch_size)\n",
    "        losses.append(loss)\n",
    "        if e % 2 == 0:\n",
    "            print('Average Loss at epoch,',e,':',loss)\n",
    "    torch.save(net.state_dict(), 'fc_with_lstm.pt')\n",
    "    plt.plot(losses)\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Test Data Prediction </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Load the Model and test data </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embeds): Embedding(5, 5)\n",
      "  (lstm): LSTM(505, 505, num_layers=2)\n",
      "  (fc1): Linear(in_features=505, out_features=100, bias=True)\n",
      "  (relu1): Sigmoid()\n",
      "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (out_act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('fc_with_lstm.pt'))\n",
    "model.eval()\n",
    "print(model)\n",
    "# load data\n",
    "positive_test_data = pd.read_fwf('positive_sample_test.txt', header = None)\n",
    "positive_test_data.columns = [\"Gene\"]\n",
    "negative_test_data = pd.read_fwf('negative_sample_test.txt', header = None)\n",
    "negative_test_data.columns = [\"Gene\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Test and Label Embeddings </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.concat([positive_test_data, negative_test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Generate output labels for test predictions </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 21\n"
     ]
    }
   ],
   "source": [
    "def test_prediction_model(data_test, labels_predicted):\n",
    "    correct, wrong = 0, 0\n",
    "    for data in data_test.itertuples():\n",
    "        data_testing = torch.tensor([vocabulary[data.Gene[i:i+window]] for i in range(0, len(data.Gene) - window + 1)], dtype=torch.long)\n",
    "        # data_test_.unsqueeze_(0)\n",
    "        # data_testing = data_test_.expand(1, batch_size, fc_layer_size)\n",
    "        labels_hat = net(data_testing)\n",
    "        labels_predicted.append(labels_hat[0])\n",
    "    for i in range(len(labels_predicted)//2 + 1):\n",
    "        if labels_predicted[i] > 0.5:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    for i in range(101, len(labels_predicted)):\n",
    "        if labels_predicted[i] > 0.5:\n",
    "            wrong += 1\n",
    "        else:\n",
    "            correct += 1\n",
    "    print(correct,wrong)\n",
    "labels_predicted = []\n",
    "test_prediction_model(data_test, labels_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Accuracy for Test predictions </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction_accuracy(labels):\n",
    "    correct, wrong = 0, 0\n",
    "    labels_hat = labels\n",
    "    for i in range(len(labels_hat)//2 + 1):\n",
    "        if labels_hat[i] > 0.5:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    for i in range(101, len(labels_hat)):\n",
    "        if labels_hat[i] > 0.5:\n",
    "            wrong += 1\n",
    "        else:\n",
    "            correct += 1\n",
    "    return (correct,wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "embedding_size = 5\n",
    "fc_layer_size = (len(positive_data.Gene[0])-(window-1))*embedding_size\n",
    "hidden_layer_size = 100\n",
    "num_layers = 2\n",
    "epochs = 500\n",
    "lr = 0.02\n",
    "train()\n",
    "# labels = []\n",
    "# test_prediction_model(data_test, labels)\n",
    "# results = test_prediction_accuracy(labels)\n",
    "# print(\"Correct Predictions:\", results[0])\n",
    "# print(\"Wrong Predictions:\", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
